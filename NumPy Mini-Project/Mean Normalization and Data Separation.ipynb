{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mean Normalization\n",
    "\n",
    "In machine learning we use large amounts of data to train our models. Some machine learning algorithms may require that the data is *normalized* in order to work correctly. The idea of normalization, also known as *feature scaling*, is to ensure that all the data is on a similar scale, *i.e.* that all the data takes on a similar range of values. For example, we might have a dataset that has values between 0 and 5,000. By normalizing the data we can make the range of values be between 0 and 1.\n",
    "\n",
    "In this lab, you will be performing a different kind of feature scaling known as *mean normalization*. Mean normalization will scale the data, but instead of making the values be between 0 and 1, it will distribute the values evenly in some small interval around zero. For example, if we have a dataset that has values between 0 and 5,000, after mean normalization the range of values will be distributed in some small range around 0, for example between -3 to 3. Because the range of values are distributed evenly around zero, this guarantees that the average (mean) of all elements will be zero. Therefore, when you perform *mean normalization* your data will not only be scaled but it will also have an average of zero. \n",
    "\n",
    "# To Do:\n",
    "\n",
    "You will start by importing NumPy and creating a rank 2 ndarray of random integers between 0 and 5,000 (inclusive) with 1000 rows and 20 columns. This array will simulate a dataset with a wide range of values. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 786 1277 1715 ... 2069 3624  179]\n [1162 4925  195 ... 3047 2622 1389]\n [3095 2590  957 ... 3655 2946 3021]\n ...\n [1664 1611 1396 ... 2996 4110 2822]\n [  41  317 4560 ... 3865 4223 4929]\n [1932 4717 3372 ... 4520 1654 4390]]\n(1000, 20)\n"
     ]
    }
   ],
   "source": [
    "# import NumPy into Python\n",
    "\n",
    "import numpy as np\n",
    "# Create a 1000 x 20 ndarray with random integers in the half-open interval [0, 5001).\n",
    "X = np.random.randint(5001, size=(1000, 20))\n",
    "print(X)\n",
    "# print the shape of X\n",
    "print(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you created the array we will mean normalize it. We will perform mean normalization using the following equation:\n",
    "\n",
    "$\\mbox{Norm_Col}_i = \\frac{\\mbox{Col}_i - \\mu_i}{\\sigma_i}$\n",
    "\n",
    "where $\\mbox{Col}_i$ is the $i$th column of $X$, $\\mu_i$ is average of the values in the $i$th column of $X$, and $\\sigma_i$ is the standard deviation of the values in the $i$th column of $X$. In other words, mean normalization is performed by subtracting from each column of $X$ the average of its values, and then by dividing by the standard deviation of its values. In the space below, you will first calculate the average and standard deviation of each column of $X$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2508.97  2502.894 2542.465 2501.919 2506.308 2464.179 2509.893 2445.523\n 2454.87  2542.267 2476.242 2597.851 2529.545 2511.723 2543.971 2481.463\n 2524.953 2470.253 2484.653 2514.266]\n[1446.64602688 1410.00132013 1443.74141271 1447.52418441 1450.41118278\n 1410.00147623 1429.55782029 1425.96353581 1466.73678453 1452.1125768\n 1451.0023058  1437.73979037 1445.00434324 1461.79448154 1441.26966323\n 1485.0490755  1437.89448528 1424.61725281 1446.75935684 1461.64208726]\n"
     ]
    }
   ],
   "source": [
    "# Average of the values in each column of X\n",
    "ave_cols = np.mean(X, axis=0)\n",
    "print(ave_cols)\n",
    "# Standard Deviation of the values in each column of X\n",
    "std_cols = np.std(X,axis=0)\n",
    "print(std_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have done the above calculations correctly, then `ave_cols` and `std_cols`, should both be vectors with shape `(20,)` since $X$ has 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20,)\n(20,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of ave_cols\n",
    "print(ave_cols.shape)\n",
    "\n",
    "# Print the shape of std_cols\n",
    "print(std_cols.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now take advantage of Broadcasting to calculate the mean normalized version of $X$ in just one line of code using the equation above. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -577.18794187  -989.8032947  -1305.15820604 ... -1518.59761398\n  -2599.82874488  -128.90958876]\n [ -853.29820414 -3817.36979358  -148.39991264 ... -2236.42674229\n  -1881.00192304 -1000.30960216]\n [-2272.76931308 -2007.51020617  -728.30110973 ... -2682.68452349\n  -2113.43694327 -2175.61937229]\n ...\n [-1221.9347777  -1248.68685025 -1062.39116947 ... -2198.99393499\n  -2948.48127524 -2032.30647753]\n [  -30.10776796  -245.70684763 -3470.27488021 ... -2836.81961239\n  -3029.54657551 -3549.69476532]\n [-1418.73677314 -3656.14889671 -2566.17695089 ... -3317.57429444\n  -1186.56643047 -3161.52566844]]\n"
     ]
    }
   ],
   "source": [
    "# Mean normalize X\n",
    "X_norm = X-(X*[ave_cols/std_cols])\n",
    "\n",
    "print(X_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have performed the mean normalization correctly, then the average of all the elements in $X_{\\tiny{\\mbox{norm}}}$ should be close to zero, and they should be evenly distributed in some small interval around zero. You can verify this by filing the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1844.4630479483496\n1832.2768264604747\n-1842.0329668637653\n"
     ]
    }
   ],
   "source": [
    "# Print the average of all the values of X_norm\n",
    "\n",
    "print(np.average(X_norm))\n",
    "# Print the average of the minimum value in each column of X_norm\n",
    "print(np.average(X_norm - X_norm.min(axis=0)))\n",
    "\n",
    "# Print the average of the maximum value in each column of X_norm\n",
    "print(np.average(X_norm - X_norm.max(axis=0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should note that since $X$ was created using random integers, the above values will vary. \n",
    "\n",
    "# Data Separation\n",
    "\n",
    "After the data has been mean normalized, it is customary in machine learnig to split our dataset into three sets:\n",
    "\n",
    "1. A Training Set\n",
    "2. A Cross Validation Set\n",
    "3. A Test Set\n",
    "\n",
    "The dataset is usually divided such that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. \n",
    "\n",
    "In this part of the lab you will separate `X_norm` into a Training Set, Cross Validation Set, and a Test Set. Each data set will contain rows of `X_norm` chosen at random, making sure that we don't pick the same row twice. This will guarantee that all the rows of `X_norm` are chosen and randomly distributed among the three new sets.\n",
    "\n",
    "You will start by creating a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this by using the `np.random.permutation()` function. The `np.random.permutation(N)` function creates a random permutation of integers from 0 to `N - 1`. Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 3, 4, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We create a random permutation of integers 0 to 4\n",
    "np.random.permutation(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Do\n",
    "\n",
    "In the space below create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`. You can do this in one line of code by extracting the number of rows of `X_norm` using the `shape` attribute and then passing it to the  `np.random.permutation()` function. Remember the `shape` attribute returns a tuple with two numbers in the form `(rows,columns)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[204 261 600 981 712 294 758 296  94 970 338 754 505 570 343  40 307 850\n 771 865  41 719 520 756 192 832 729 924 499 863 783 835  21 820 268 528\n 344 677 359 748 412 484 384 455 250 521 731 608 493 797 223 413 123 439\n 630 264 613 256 356 930  45 720 205 541 102 814 472 477 454 846 501 225\n 300 315 958 458 580 422 112 306 561 213 993 162 945 904 311 826 716  74\n 305 218 999 399 659 898 130 103 885 379 639 695 743 497 407 259 852 687\n 920 188 775 544 701 723  67 560 461  51 232 700 416 548 711 636 215 618\n 220 738 968 891 152 538 126  93 864 974 502 940 417 923 325 880  84 876\n  48 117 660 601 158 831  85 150 246 915 989 387 928  52 357 127 511 807\n  97 734 182 894 243 746 241 512 327 423 822 985 301 173 593   7 391 887\n 938 525 889 408 196 575 871 706 532 884  20 688  73 536 169 691  78 492\n 462 679 892 905  79 257 577 901  61 436 549  95 153  36 125 490 947 120\n 331 730 287  98 322 394 473 283 556 808 444 906 592 518 318 742 288 811\n  81 689 878 481 390 441 685 802 380 230 179  92 190 281 933 270 937 827\n 757 142 609 568 332 364 353 914 739 598 437 510 867 530 373 465 838 137\n 274 285 258 627 978 991 333 140 110  26 604 129 943 692 722 132 478 694\n 368 759 579   3 272 295 233 942 320  60 108  91  80 875 238 486 291 596\n 135 383 599 841  86 165 873 634  99 406 453 640 124 803 952 348 203 515\n 198 415 847  39 155 393 931 726 421 855 886 969 576 367 683 680 652 553\n 435 471  27 645 747 237 509 319 279 533 433 781  68 611 374 767 992 805\n 900 954 895 842 480 668 893 922 381 347 623 749 725 467  44 542 910 330\n 705 813 361 736 986 632 795 971 612 199 709 201 539  11 843 324 276 224\n 638 790 200 111 607  53 286  18 620 897 266 535 921 168 667 297 377 798\n 789 487  59 649 340 935 572 308 708 430 804 888 671 245  50 400 289 582\n 982 488 128 961 106 116 447 183 574 963 351 929 178 597 529 728 314  58\n 522 290 606 801 605 271 703 313 737 794 919 927 105 159 310 304 118 513\n 678 483 244 468 355  24 635 207  22  31 176 186 780 866 745 817 459  89\n 109 163 653 160 715 916 221 263 442 470 389 750 912 718 874 269 563 614\n 655 265  34 312 799 984 219 890 661 909  42 774 872 177 206 195 669 721\n 166 879 853 962 194 354 197 445 375 545 588 326 401  82 410 239 464 571\n 226 983 877 768  17 868 988  10 236 161 594 371 990 209 809 156 242 254\n 566 591  23 751   0 134 452 405  30 616 911  14 559 321 810 666 143 247\n 115 372 766 251 185 856 994 796 573  90 100 602 997 784 764 686 277 672\n 741 785 567 376 252 643 141 476 395 581  66 960  29 837 977 482 670 836\n 693 828 684 821 834 136  25 154 189 555 339   8 494  16  69  76 663 727\n 845 903 578 298 793 113 674 506 882 752 334 624 508 980 587 651 932 557\n 255  46 844 396 862 363  57 370 610 299 438 234 170 621 949 650 104 658\n 792 902 583 959 830 485 212 369 164 787 293  83 699 761 917 637 443 769\n 336 121 858  32 457 953  96 328 469 503 388 227 772 840 414 777 342 740\n 362 540 642 622 358  28 463  72 778 426 303 187 148 496  37 534 386 174\n 839 995 815 181 420 585 714  54 460 631 976 527 941 543 552 193 806 763\n  38  70 317 446 996 495 595 302 979 365  64 210  49 316 216 498 523 133\n 590 366 323 966  15 517 569 633 516 603 425  87 925 341 248 345 644 617\n 240   1 167 260 157  62 119 676 138 235 710 432 825 704 619 625 211 475\n 896   4 214  55 955 908 647 717 398  63 411 589 786 429 648 329 690 948\n 172 629 662 944 744 404  43 378  33 267 292 519 122 951 280 657 424 431\n 531 800 474 967 782 762 696 586 427 428 918 965 175 656 973 456  75 881\n 537 776 217 950 735 753 956 584 998 448 500 664 707 899 883 816 698 760\n 628 151 869 907 231 402 346 713 848 849 149 682 131 946 139 392 514 857\n 934 202 829 337 284 697 972  71 360 275 913 615 504  47 449  88 681 146\n 733 253 403 550 673 870  19 114 249  35   6 397  12 675 526 824 352 975\n 418 779 228 524 382 335 479 854 818 282 145 489 936 765 732 147   5 466\n  13 755 791 184 440 812 409   9 823 262 564 554 773 987 939 565 964  65\n  56 273 641 551 654 419 665 507 208 229 547 851 819 171 833 626 491 278\n 957 558  77 191 222 860 702 861 859 350 385 562 770 107 309 724   2 349\n 434 451 546 788 926 646 144 180 450 101]\n"
     ]
    }
   ],
   "source": [
    "# Create a rank 1 ndarray that contains a random permutation of the row indices of `X_norm`\n",
    "row_indices =np.random.permutation(X_norm.shape[0])\n",
    "print(row_indices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you can create the three datasets using the `row_indices` ndarray to select the rows that will go into each dataset. Rememeber that the Training Set contains 60% of the data, the Cross Validation Set contains 20% of the data, and the Test Set contains 20% of the data. Each set requires just one line of code to create. Fill in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make any necessary calculations.\n",
    "# You can save your calculations into variables to use later.\n",
    "\n",
    "\n",
    "# Create a Training Set\n",
    "X_train = row_indices[:12]\n",
    "\n",
    "# Create a Cross Validation Set\n",
    "X_crossVal = row_indices[7:8]\n",
    "\n",
    "# Create a Test Set\n",
    "X_test = row_indices[81:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you performed the above calculations correctly, then `X_tain` should have 600 rows and 20 columns, `X_crossVal` should have 200 rows and 20 columns, and `X_test` should have 200 rows and 20 columns. You can verify this by filling the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12,)\n(1,)\n(19,)\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of X_train\n",
    "print(X_train.shape)\n",
    "\n",
    "# Print the shape of X_crossVal\n",
    "print(X_crossVal.shape)\n",
    "\n",
    "# Print the shape of X_test\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
